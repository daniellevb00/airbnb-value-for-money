## RMarkdown dPREP project team 3: InsideAirbnb data ##

Research question: How do different attribute features influence the listing price? (which the most/least?) And does this actually translate into high price/quality ratio review scores by consumers? 

#### Variables dictionary (of our final generated dataset): 
New variable name | Definition    
------------------|----------------------------------------
id                | Airbnb's unique identifier for the listing
list_name         | Name of the listing
host_id           | Airbnb's unique identifier for the host/user
neighbourhood     | Neighbourhood the listing is located
room_type         | Homes grouped as room types, incl. 'Entire place', 'Private room', 'Shared room', 'Entire place'
accommodates      | The maximum capacity of the listing
price             | Daily price of the listing in $
n_reviews         | Total number of reviews per listing
rev_rating        | Review score for rating 
rev_accuracy      | Review score for accuracy 
rev_clean         | Review score for cleanliness
rev_checkin       | Review score for checkin
rev_comm          | Review score for communication
rev_location      | Review score for location
rev_value         | Review score for value
n_reviews_month   | Number of reviews per listing per month 

### Step 0: Starting-up
```{r}
#Loading the packages
library(tidyverse) 
library(dplyr)
library(ggplot2)
library(readr)
library(stringr)
```
New way to programmatically download data from the web (doesn't work fully yet so I wrote the code as comments)
```{r}
#Programmatically downloading the data from InsideAirbnb.com for Amsterdam. 
#download_data <- function(url, filename, filepath){ #create a function to download the data
  #dir.create(filepath) #create a directory 
  #download.file(url=url, destfile = paste0(filepath,filename)) #download the file
#}
#download_data(url = 'http://data.insideairbnb.com/the-netherlands/north-holland/amsterdam/2021-09-07/data/listings.csv.gz', filename='Listings.csv',filepath='data/')
```

```{r}
#Inspecting the raw data
#airbnb<-read.table('http://data.insideairbnb.com/the-netherlands/north-holland/amsterdam/2021-09-07/data/listings.csv.gz', sep =',', header=TRUE)
#head(airbnb) 
#summary(airbnb)
```

What we used before (remove if the prior works):
```{r}
download.file('http://data.insideairbnb.com/the-netherlands/north-holland/amsterdam/2021-09-07/data/listings.csv.gz', 'Listings.csv')
listings<-read.csv('Listings.csv')
head(listings)
```

### Step 1: Data transformation 
#### Filtering columns
We narrow down the dataset to what we like to focus on. 
```{r}
cols_to_keep <- c('id', 'host_id', 'price', 'room_type','accommodates', 'minimum_nights', 'maximum_nights', 'bedrooms', 'beds', 'amenities','number_of_reviews', 'review_scores_rating','review_scores_accuracy','review_scores_cleanliness','review_scores_checkin','review_scores_communication', 'review_scores_location', 'review_scores_value','reviews_per_month', 'license','host_listings_count','host_is_superhost','host_acceptance_rate','host_response_time','host_response_rate','instant_bookable')
df<-listings[,which(colnames(listings)%in%cols_to_keep)]
ncol(df) #we keep 27 columns 
```
#### Renaming columns
Now we rename the columns that we kept for clarity. 
```{r}
colnames(df) #check all the column names of the dataset
df1 <- df %>%
  rename(rev_accuracy = review_scores_accuracy,
         rev_comm = review_scores_communication,
         rev_clean = review_scores_cleanliness,
         rev_location = review_scores_location,
         rev_value = review_scores_value,
         rev_checkin = review_scores_checkin,
         rev_rating = review_scores_rating,
         n_reviews = number_of_reviews,
         n_reviews_month = reviews_per_month,
         n_host_listings = host_listings_count,
         min_nights = minimum_nights,
         max_nights = maximum_nights,
         host_accept_rate = host_acceptance_rate,
         superhost = host_is_superhost)
head(df1)
```

#### Correcting dummy variables and NA values
```{r}
#Making instant_bookable, superhost, license binary variables
df1$superhost<-ifelse(df1$superhost=='t',1,0) #1=superhost, 0 = not superhost
df1$instant_bookable<-ifelse(df1$instant_bookable=='t',1,0) #1=yes, 0=no
df1$license<-ifelse(df1$license=='',0,1) #1=licensed, 0=not licensed. 
#Replacing N/As with NA in host_response_time, host_response_rate, host_acceptance_rate
df1$host_response_time[df1$host_response_time=='N/A'] <- NA
df1$host_response_rate[df1$host_response_rate=='N/A'] <- NA
df1$host_accept_rate[df1$host_accept_rate=='N/A'] <- NA
```
#### Creating separate columns for each amenity
We now split the values of the amenity column into columns of their own (at least if we want to use them in our analysis). We identify several attribute categories: 
* Safety attributes = 
* Comfort attributes = 
* Space attributes = 
* Host attributes = 
First we do some cleaning in the amenities column: 
```{r}
df2<-df1
#Clean up the amenities column: remove brackets, '', and whitespace. 
df2$amenities<-gsub('\\[', '',df2$amenities) 
df2$amenities<-gsub('\\]', '',df2$amenities)
df2$amenities<-gsub('\\"', '',df2$amenities) 
df2$amenities<-gsub('\\"', '',df2$amenities)
df2$amenities<-gsub(',', ';',df2$amenities) 
df2$amenities<-gsub(' ','', df2$amenities) 
#Filter out the empty amenities rows
df2<-df2%>%filter(df1$amenities!='')
#Change the amenity names to lowercase (and put them into a new column)
df2<-df2%>%mutate(amenities_lower=str_to_lower(amenities)) 
head(df2$amenities_lower)
df3<-df2%>%select(-amenities) #we remove the old column now
```
Then, we construct the amenities columns using a combination of ifelse() and grepl(), as an alternative to using pivot_wider(). 
```{r}
#SPACE ATTRIBUTES
df3$balcony<-ifelse(grepl('balcony',df3$amenities_lower),1,0)
df3$lake_access<-ifelse(grepl('lakeaccess',df3$amenities_lower),1,0)
df3$waterfront<-ifelse(grepl('waterfront',df3$amenities_lower),1,0)
df3$free_parking<-ifelse(grepl('freeparking',df3$amenities_lower),1,0)
df3$private_entry<-ifelse(grepl('privateentrance',df3$amenities_lower),1,0)
#QUALITY ATTRIBUTES
#mainly the star rating columns are already included
#FREEBIES ATTRIBUTES
df3$kitchen <- ifelse(grepl('kitchen', df3$amenities_lower),1,0)
df3$oven<-ifelse(grepl('oven',df3$amenities_lower),1,0)
df3$stove<-ifelse(grepl('stove',df3$amenities_lower),1,0)
df3$wifi<-ifelse(grepl('wifi',df3$amenities_lower),1,0)
df3$fridge<-ifelse(grepl('refrigerator',df3$amenities_lower),1,0)
df3$iron<-ifelse(grepl('iron',df3$amenities_lower),1,0)
df3$bed_linens<-ifelse(grepl('bedlinens',df3$amenities_lower),1,0)
df3$tv<-ifelse(grepl('tv',df3$amenities_lower),1,0)
df3$dryer<-ifelse(grepl('dryer',df3$amenities_lower),1,0)
df3$coffee_maker<-ifelse(grepl('coffeemaker',df3$amenities_lower),1,0)
df3$heating<-ifelse(grepl('heating',df3$amenities_lower),1,0)
#HOST QUALITY ATTRIBUTES
df3$host_greet<-ifelse(grepl('hostgreetsyou',df3$amenities_lower),1,0)
#others are mainly already the dataset itself
#SAFETY ATTRIBUTES
df3$fire_extinguisher<-ifelse(grepl('fireextinguisher',df3$amenities_lower),1,0)
df3$smoke_alarm<-ifelse(grepl('smokealarm',df3$amenities_lower),1,0)
df3$security_cameras<-ifelse(grepl('securitycameras',df3$amenities_lower),1,0)
df3$carbon_monoxide_alarm<-ifelse(grepl('carbonmonoxidealarm',df3$amenities_lower),1,0)
df3$smart_lock<-ifelse(grepl('smartlock',df3$amenities_lower),1,0)
class(df3$smart_lock) #columns are seen as numerics, while they should be logicals.

df4<-df3%>%select(-amenities_lower) #after generating all necessary columns, delete the amenities_lower column 
```

### Step 3: Cleaning the data
#### Checking and correcting variables' datatypes
```{r}
lapply(df4, class)
df4$price<-as.numeric(gsub('\\$','',df4$price)) #make price numeric: remove the $ sign
#convert some character variables into factors
df4$host_response_time<-as.factor(df4$host_response_time)
df4$room_type<-as.factor(df4$room_type)
#convert some numeric variables into logicals (binary variables)
#this changes binary 0,1 variables into TRUE/FALSE(!)
df4$license<-as.logical(df4$license)
df4$superhost<-as.logical(df4$superhost)
df4$instant_bookable<-as.logical(df4$instant_bookable)
#convert the amenities columns from numerics into logicals (binary variables)
#SPACE ATTRIBUTES
df4$balcony<-as.logical(df4$balcony)
df4$lake_access<-as.logical(df4$lake_access)
df4$waterfront<-as.logical(df4$waterfront)
df4$free_parking<-as.logical(df4$free_parking)
df4$private_entry<-as.logical(df4$private_entry)
#FREEBIES ATTRIBUTES
df4$kitchen<-as.logical(df4$kitchen)
df4$oven<-as.logical(df4$oven)
df4$stove<-as.logical(df4$stove)
df4$wifi<-as.logical(df4$wifi)
df4$fridge<-as.logical(df4$fridge)
df4$iron<-as.logical(df4$iron)
df4$bed_linens<-as.logical(df4$bed_linens)
df4$tv<-as.logical(df4$tv)
df4$dryer<-as.logical(df4$dryer)
df4$coffee_maker<-as.logical(df4$coffee_maker)
df4$heating<-as.logical(df4$heating)
#HOST QUALITY ATTRIBUTES
df4$host_greet<-as.logical(df4$host_greet)
#SAFETY ATTRIBUTES
df4$fire_extinguisher<-as.logical(df4$fire_extinguisher)
df4$smoke_alarm<-as.logical(df4$smoke_alarm)
df4$security_cameras<-as.logical(df4$security_cameras)
df4$carbon_monoxide_alarm<-as.logical(df4$carbon_monoxide_alarm)
df4$smart_lock<-as.logical(df4$smart_lock)

sapply(df4, class)
```

#### Filtering for missings/0 values
```{r}
df5<-df4
df5<-df5%>%filter(price != '0') #removing listings with price=$0.00
df5<-df5%>%filter(n_reviews !='0') #exclude listings with no reviews to provide more accurate estimates (listings with at least one review are said to be already closer to the equilibrium price, which may be important here!)
#df5<-df5%>%filter(rev_rating != 0.00, rev_clean !=0.00, rev_accuracy !=0.00, rev_comm !=0.00, rev_location !=0.00,rev_value !=0.00) #when rev_rating = 0.00, all other ratings for all other categories were NA so this data isnt useable -> now the review columns don't contain NA values anymore either. 
summary(df5)
head(df5)
```

#### Checking range constraints
Ensuring that the star ratings do really fall between 1 and 5. 
```{r}
#for rev_rating (passed test)
breaks<-unique(c(min(df5$rev_rating),1,5,max(df5$rev_rating))) #wrapped with unique() to omit the error of 'breaks are not unique' message
ggplot(df5,aes(rev_rating))+geom_histogram(breaks=breaks)
#for rev_accuracy (passed test)
breaks<-unique(c(min(df5$rev_accuracy),1,5,max(df5$rev_accuracy))) 
ggplot(df5,aes(rev_accuracy))+geom_histogram(breaks=breaks)
#for rev_clean (passed test)
breaks<-unique(c(min(df5$rev_clean),1,5,max(df5$rev_clean))) 
ggplot(df5,aes(rev_clean))+geom_histogram(breaks=breaks)
#for rev_checkin (passed test)
breaks<-unique(c(min(df5$rev_checkin),1,5,max(df5$rev_checkin))) 
ggplot(df5,aes(rev_checkin))+geom_histogram(breaks=breaks)
#for rev_comm (passed test)
breaks<-unique(c(min(df5$rev_comm),1,5,max(df5$rev_comm)))
ggplot(df5,aes(rev_comm))+geom_histogram(breaks=breaks)
#for rev_location (passed test)
breaks<-unique(c(min(df5$rev_location),1,5,max(df5$rev_location))) 
ggplot(df5,aes(rev_location))+geom_histogram(breaks=breaks)
#for rev_value (passed test)
breaks<-unique(c(min(df5$rev_value),1,5,max(df5$rev_value)))
ggplot(df5,aes(rev_value))+geom_histogram(breaks=breaks)
```

#### Checking uniqueness constraints  
```{r}
#checking for full duplicates
duplicated(df5)
sum(duplicated(df5)) #0 full duplicates (passed test)
#checking for partial duplicates
df5%>%count(id)%>%filter(n>1) #0 partial duplicates (passed test)
df5%>%count(host_id,price)%>%filter(n>1) #some host-id and price combinations are the same, but no id is the same (so these must be similar but different listings we suppose)
```

### Step 3: Data wrangling
#### Arranging, mutating, and summarizing 
```{r}
#arranging based on price
df6<-df5%>%arrange(price) 
#creating a new column for average star rating based on the 7 categories
df6<-df6%>%mutate(mean_review = ((rev_rating+rev_accuracy+rev_clean+rev_checkin+rev_comm+rev_location+rev_value)/7))
head(df6)
summary(df6)
```

### Step 4: Data exploration   
Some summary statistics. 
```{r}
#overall rating per price class
overallrating_price<-df6%>%group_by(price)%>%summarize(mean_rating=mean(rev_rating)) 
#average review scores per price class
df6%>%group_by(price)%>%summarize(mean_accuracy=mean(rev_accuracy),
                                       mean_comm=mean(rev_comm),
                                       mean_clean=mean(rev_clean),
                                       mean_location=mean(rev_location),
                                       mean_checkin=mean(rev_checkin),
                                       mean_value=mean(rev_value))
```


